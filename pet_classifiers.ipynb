{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d99bc87-ae23-4ac9-86f8-3a9c3f19479c",
   "metadata": {},
   "source": [
    "## The goal of this notebook is to train classifiers for PET, T1 and Generated PET images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f2eb0-9fb7-4856-a392-1a4684c96503",
   "metadata": {},
   "source": [
    "## Training in low data regime, so I've done my best to avoid overfitting.\n",
    "\n",
    "PET data are crop centered and downsampled to half of their dimensions. Images are scaled indipendently to 0,1 <br>\n",
    "Random Gaussian Noise, Flip and gaussian smoothing are augmentations used in training phase <br>\n",
    "\n",
    "The model is a Classifier based on depthwise separable convolutions. <br>\n",
    "The last layer is a BayesianLinear liner, so instead of learning the optimal parameter, the model try to learn a distribution of parameters. This is equivalent to infinite network ensembling. <br>\n",
    "Adam optimizer is used with class weight to deal with unbalanced classes and regularization on weight_decay to deal with overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1faf7bd2-ad44-43e9-88d3-0f6e52f5a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m (\u001b[33mtorvergatafmri\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "from os.path import join as opj\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from unet3D import *\n",
    "from torchsummary import summary\n",
    "import monai\n",
    "from monai.transforms import *\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import ssim\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "wandb.login()\n",
    "from network import *\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from monai.networks.nets import *\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import torchbnn as bnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d01115e-8b28-4223-bdde-51b73e517dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/home/matteo/data/MRI-PET-AI\"\n",
    "config={}\n",
    "\n",
    "cases=os.listdir(base_path)\n",
    "exclude=['Scripts','temp','SubjectList.txt','Bay_7_Reconstruction_Log.xlsx','PBRKOA_KOA003_010818']\n",
    "\n",
    "cases=[i for i in cases if i not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0a0eba-c3f1-493f-a9d2-cdba8feb179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={\"HC\":0, \"CLB\":1, \"KOA\":2}\n",
    "labels=[]\n",
    "for c in cases:\n",
    "    cl=None\n",
    "    if \"HC\" in c:\n",
    "        cl=\"HC\"\n",
    "    elif \"CLB\" in c:\n",
    "        cl=\"CLB\"\n",
    "    elif \"KOA\" in c:\n",
    "        cl=\"KOA\"\n",
    "    if cl is not None:\n",
    "        labels.append(label_dict[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b9792f-f687-459a-acce-2d39509d3196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases=[os.path.join(base_path,i) for i in cases if i not in exclude]\n",
    "len(labels),len(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ada05f-f8cc-4ab4-9011-66a4f42b2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train cases: 163 test cases: 41\n"
     ]
    }
   ],
   "source": [
    "train_cases,test_cases,train_labels,test_labels=train_test_split(cases,labels,test_size=0.20,random_state=42)\n",
    "# train_cases,val_cases,train_labels,val_labels=train_test_split(cases,labels,test_size=0.2)\n",
    "\n",
    "\n",
    "print(f\"[INFO] train cases: {len(train_cases)} test cases: {len(test_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af893492-cb3a-4c95-89e1-4d454ac0f8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8711656441717791, 0.5705521472392638, 0.558282208588957]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=[1-np.sum(np.array(train_labels)==i)/len(train_labels) for i in range(len(set(label_dict.values())))]\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10efb577-055e-41e6-8031-de43e0e7cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"[INFO] train unbalance: {np.sum(train_labels)/len(train_labels)} test unbalance: {np.sum(test_labels)/len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aad1102-b08c-4319-823d-3979ed2e26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIPETDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels,roi=(96,96,96),modality=\"PET\", transform=None, target_transform=None,out_mask=False):\n",
    "        self.paths = paths\n",
    "        self.labels=labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.roi=roi\n",
    "        self.out_mask=out_mask\n",
    "        self.modality=modality\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        images_path=glob.glob(opj(self.paths[idx],\"*.nii.gz\"))\n",
    "        t1_path=[i for i in images_path if \"T1\" in i][0]\n",
    "        pet_path=[i for i in images_path if \"_suv_\" in i][0]\n",
    "        \n",
    "        t1=nib.load(t1_path)\n",
    "        pet=nib.load(pet_path)\n",
    "        \n",
    "        assert t1.shape==pet.shape\n",
    "        half_shape=[s//2 for s in t1.shape]\n",
    "        half_roi=[s//2 for s in self.roi]\n",
    "        dim_0_start=half_shape[0]-half_roi[0]\n",
    "        dim_0_end=half_shape[0]+half_roi[0]\n",
    "\n",
    "        dim_1_start=half_shape[1]-half_roi[1]\n",
    "        dim_1_end=half_shape[1]+half_roi[1]\n",
    "\n",
    "        dim_2_start=half_shape[2]-half_roi[2]\n",
    "        dim_2_end=half_shape[2]+half_roi[2]\n",
    "        \n",
    "        ##choose what data we need to load\n",
    "        label=self.labels[idx]\n",
    "        \n",
    "        if self.modality==\"PET\":\n",
    "            pet=pet.dataobj[dim_0_start:dim_0_end,dim_1_start:dim_1_end,dim_2_start:dim_2_end]\n",
    "            pet=torch.Tensor(np.expand_dims(pet,0))\n",
    "            if self.target_transform:\n",
    "                pet = self.target_transform(pet)\n",
    "                \n",
    "            return pet,label\n",
    "                \n",
    "                \n",
    "            \n",
    "        elif self.modality==\"MRI\":\n",
    "            t1=t1.dataobj[dim_0_start:dim_0_end,dim_1_start:dim_1_end,dim_2_start:dim_2_end]\n",
    "            t1=torch.Tensor(np.expand_dims(t1,0))\n",
    "            if self.transform:\n",
    "                t1 = self.transform(t1)\n",
    "                \n",
    "            return t1,label\n",
    "        \n",
    "        elif self.modality==\"both\":\n",
    "            pet=pet.dataobj[dim_0_start:dim_0_end,dim_1_start:dim_1_end,dim_2_start:dim_2_end]\n",
    "            pet=torch.Tensor(np.expand_dims(pet,0))\n",
    "            if self.target_transform:\n",
    "                pet = self.target_transform(pet)\n",
    "                \n",
    "            t1=t1.dataobj[dim_0_start:dim_0_end,dim_1_start:dim_1_end,dim_2_start:dim_2_end]\n",
    "            t1=torch.Tensor(np.expand_dims(t1,0))\n",
    "            if self.transform:\n",
    "                t1 = self.transform(t1)\n",
    "            \n",
    "\n",
    "            if self.out_mask:\n",
    "                mask=(t1>0)*1.\n",
    "                return t1,pet,mask,label\n",
    "            else:\n",
    "                return t1,pet, label\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac6919d4-84e7-40e6-8659-0bc6ecd25aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=16\n",
    "modality=\"PET\"\n",
    "config[\"BS\"]=BS\n",
    "config[\"modality\"]=modality\n",
    "\n",
    "transform_mri=Compose([ScaleIntensityRangePercentiles(1,99,0,1)])\n",
    "transform_pet=Compose([Spacing(pixdim=(2,2,2),image_only=True),\n",
    "                       ScaleIntensity(0,1),\n",
    "                       RandFlip(0.3,spatial_axis=[1,2,]),\n",
    "                       RandGaussianSmooth(sigma_x=(0.25, 1.5), sigma_y=(0.25, 1.5), sigma_z=(0.25, 1.5), prob=0.1),\n",
    "                      ])\n",
    "\n",
    "transform_pet_test=Compose([Spacing(pixdim=(2,2,2),image_only=True),\n",
    "                       ScaleIntensity(0,1),])\n",
    "\n",
    "#transform_pet=None\n",
    "\n",
    "train_dataset=MRIPETDataset(train_cases,train_labels,modality=modality,transform=transform_mri,target_transform=transform_pet)\n",
    "test_dataset=MRIPETDataset(test_cases,test_labels,modality=modality,transform=transform_mri,target_transform=transform_pet_test)\n",
    "\n",
    "\n",
    "train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=BS,shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=BS,shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47651094-af32-4dac-97e5-0cca75255ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(train_dataset))\n",
    "\n",
    "x.shape,x.max(),x.min()\n",
    "in_shape=x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f291f3-b91f-4a1d-a095-52e6e3deeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=[32,64,128]\n",
    "kernel_size=3\n",
    "\n",
    "config[\"channels\"]=channels\n",
    "config[\"kernel_size\"]=kernel_size\n",
    "\n",
    "\n",
    "model=BayesianClassifier(in_shape=in_shape,classes=len(set(label_dict.values())),channels=channels,strides=[2,2,2],kernel_size=kernel_size,depthwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c207af3-d9aa-4336-995a-45f3204ebb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 8, 24, 24, 24]             224\n",
      "            Conv3d-2        [-1, 1, 24, 24, 24]              28\n",
      "            Conv3d-3        [-1, 8, 24, 24, 24]              16\n",
      "    DepthSepConv3d-4        [-1, 8, 24, 24, 24]               0\n",
      "    InstanceNorm3d-5        [-1, 8, 24, 24, 24]               0\n",
      "             PReLU-6        [-1, 8, 24, 24, 24]               1\n",
      "            Conv3d-7        [-1, 8, 24, 24, 24]             224\n",
      "            Conv3d-8        [-1, 8, 24, 24, 24]              72\n",
      "    DepthSepConv3d-9        [-1, 8, 24, 24, 24]               0\n",
      "   InstanceNorm3d-10        [-1, 8, 24, 24, 24]               0\n",
      "            PReLU-11        [-1, 8, 24, 24, 24]               1\n",
      "     ResidualUnit-12        [-1, 8, 24, 24, 24]               0\n",
      "           Conv3d-13       [-1, 16, 12, 12, 12]           3,472\n",
      "           Conv3d-14        [-1, 8, 12, 12, 12]             224\n",
      "           Conv3d-15       [-1, 16, 12, 12, 12]             144\n",
      "   DepthSepConv3d-16       [-1, 16, 12, 12, 12]               0\n",
      "   InstanceNorm3d-17       [-1, 16, 12, 12, 12]               0\n",
      "            PReLU-18       [-1, 16, 12, 12, 12]               1\n",
      "           Conv3d-19       [-1, 16, 12, 12, 12]             448\n",
      "           Conv3d-20       [-1, 16, 12, 12, 12]             272\n",
      "   DepthSepConv3d-21       [-1, 16, 12, 12, 12]               0\n",
      "   InstanceNorm3d-22       [-1, 16, 12, 12, 12]               0\n",
      "            PReLU-23       [-1, 16, 12, 12, 12]               1\n",
      "     ResidualUnit-24       [-1, 16, 12, 12, 12]               0\n",
      "           Conv3d-25          [-1, 32, 6, 6, 6]          13,856\n",
      "           Conv3d-26          [-1, 16, 6, 6, 6]             448\n",
      "           Conv3d-27          [-1, 32, 6, 6, 6]             544\n",
      "   DepthSepConv3d-28          [-1, 32, 6, 6, 6]               0\n",
      "   InstanceNorm3d-29          [-1, 32, 6, 6, 6]               0\n",
      "            PReLU-30          [-1, 32, 6, 6, 6]               1\n",
      "           Conv3d-31          [-1, 32, 6, 6, 6]             896\n",
      "           Conv3d-32          [-1, 32, 6, 6, 6]           1,056\n",
      "   DepthSepConv3d-33          [-1, 32, 6, 6, 6]               0\n",
      "     ResidualUnit-34          [-1, 32, 6, 6, 6]               0\n",
      "          Flatten-35                 [-1, 6912]               0\n",
      "      BayesLinear-36                    [-1, 3]               0\n",
      "          Reshape-37                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 21,929\n",
      "Trainable params: 21,929\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.42\n",
      "Forward/backward pass size (MB): 12.37\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 12.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,in_shape,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33588994-0baf-43c1-993a-3f86f212fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianClassifier(\n",
       "  (net): Sequential(\n",
       "    (layer_0): ResidualUnit(\n",
       "      (conv): Sequential(\n",
       "        (unit0): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "              (1): Conv3d(1, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (unit1): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=8)\n",
       "              (1): Conv3d(8, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    )\n",
       "    (layer_1): ResidualUnit(\n",
       "      (conv): Sequential(\n",
       "        (unit0): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=8)\n",
       "              (1): Conv3d(8, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (unit1): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=16)\n",
       "              (1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    )\n",
       "    (layer_2): ResidualUnit(\n",
       "      (conv): Sequential(\n",
       "        (unit0): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16)\n",
       "              (1): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (unit1): Convolution(\n",
       "          (conv): DepthSepConv3d(\n",
       "            (depthwise_separable_conv): Sequential(\n",
       "              (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32)\n",
       "              (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (reshape): Reshape()\n",
       "  (final): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): BayesLinear(prior_mu=0.0, prior_sigma=0.1, in_features=6912, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda:0\"\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a770cc3-3055-4ab1-bd13-15d2b331bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))\n",
    "optim=torch.optim.Adam(model.parameters(),lr=3e-4,weight_decay=1e-3)\n",
    "\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "kl_weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0285d-572f-48ba-bc4d-13fd641e232d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6c1da06-04fd-4ada-a400-6af34f2ff969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4svmlu11) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-pyramid-15</strong>: <a href=\"https://wandb.ai/torvergatafmri/MRI2PET/runs/4svmlu11\" target=\"_blank\">https://wandb.ai/torvergatafmri/MRI2PET/runs/4svmlu11</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220814_173358-4svmlu11/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4svmlu11). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/MRI2PET/wandb/run-20220814_173403-2qw2winz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/torvergatafmri/MRI2PET/runs/2qw2winz\" target=\"_blank\">scarlet-frost-16</a></strong> to <a href=\"https://wandb.ai/torvergatafmri/MRI2PET\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/torvergatafmri/MRI2PET/runs/2qw2winz?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbd9d64c670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"MRI2PET\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19f4960-1907-4243-b743-f3b2424364e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.803244411945343: 100%|█████████████████████████████████| 11/11 [00:26<00:00,  2.40s/it]\n",
      "val epoch 0 val loss: 4.714984893798828: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.15s/it]\n",
      "epoch 1 loss: 5.040626525878906: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 1 val loss: 3.308483123779297: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 2 loss: 3.186206102371216: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 2 val loss: 8.193093299865723: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 3 loss: 0.02745322324335575: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 3 val loss: 2.959501266479492: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 4 loss: 1.2528403997421265: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 4 val loss: 4.005277633666992: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "epoch 5 loss: 3.1648030281066895: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 5 val loss: 1.7581861019134521: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 6 loss: 0.520052969455719: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.31s/it]\n",
      "val epoch 6 val loss: 2.3343188762664795: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.15s/it]\n",
      "epoch 7 loss: 4.751847743988037: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 7 val loss: 4.115786552429199: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.15s/it]\n",
      "epoch 8 loss: 0.17421238124370575: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 8 val loss: 3.759401559829712: 100%|███████████████████████████| 3/3 [00:06<00:00,  2.17s/it]\n",
      "epoch 9 loss: 3.3630998134613037: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.34s/it]\n",
      "val epoch 9 val loss: 3.5321245193481445: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "epoch 10 loss: 1.0476781129837036: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.31s/it]\n",
      "val epoch 10 val loss: 3.337303876876831: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 11 loss: 1.2870503664016724: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.31s/it]\n",
      "val epoch 11 val loss: 1.9945554733276367: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 12 loss: 4.267717361450195: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 12 val loss: 3.191631555557251: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 13 loss: 5.356544494628906: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 13 val loss: 3.1381993293762207: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 14 loss: 2.703218936920166: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 14 val loss: 5.322569370269775: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "epoch 15 loss: 4.073311805725098: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 15 val loss: 4.876754283905029: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.15s/it]\n",
      "epoch 16 loss: 1.5133029222488403: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 16 val loss: 2.0133209228515625: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 17 loss: 0.6648193597793579: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 17 val loss: 2.958547830581665: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 18 loss: 0.9397062659263611: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 18 val loss: 0.9693583846092224: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 19 loss: 1.3413894176483154: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 19 val loss: 2.3168272972106934: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.15s/it]\n",
      "epoch 20 loss: 2.35263729095459: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 20 val loss: 3.846428871154785: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 21 loss: 2.282883644104004: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 21 val loss: 3.1563162803649902: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 22 loss: 1.9915810823440552: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 22 val loss: 2.3661468029022217: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 23 loss: 0.09987705945968628: 100%|██████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 23 val loss: 3.0851900577545166: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 24 loss: 0.4714511036872864: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.31s/it]\n",
      "val epoch 24 val loss: 1.6953020095825195: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.24s/it]\n",
      "epoch 25 loss: 5.733323097229004: 100%|████████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 25 val loss: 6.495363712310791: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "epoch 26 loss: 2.3067164421081543: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 26 val loss: 3.443209171295166: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.16s/it]\n",
      "epoch 27 loss: 2.37320876121521: 100%|█████████████████████████████████| 11/11 [00:25<00:00,  2.28s/it]\n",
      "val epoch 27 val loss: 2.667280912399292: 100%|██████████████████████████| 3/3 [00:06<00:00,  2.16s/it]\n",
      "epoch 28 loss: 1.2290847301483154: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.29s/it]\n",
      "val epoch 28 val loss: 4.8692240715026855: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 29 loss: 0.9323874115943909: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 29 val loss: 2.2775778770446777: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n",
      "epoch 30 loss: 1.9078196287155151: 100%|███████████████████████████████| 11/11 [00:25<00:00,  2.30s/it]\n",
      "val epoch 30 val loss: 1.4733678102493286: 100%|█████████████████████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "epoch 31 loss: 3.5690062046051025:  73%|███████████████████████▎        | 8/11 [00:21<00:08,  2.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m y_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     18\u001b[0m y_pred_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     21\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m     x,y\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device),y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mMRIPETDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     pet\u001b[38;5;241m=\u001b[39m\u001b[43mpet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim_0_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mdim_0_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim_1_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mdim_1_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim_2_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mdim_2_end\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     42\u001b[0m     pet\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mexpand_dims(pet,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/arrayproxy.py:397\u001b[0m, in \u001b[0;36mArrayProxy.__getitem__\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, slicer):\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/arrayproxy.py:358\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    356\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/arrayproxy.py:339\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array_from_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape,\n\u001b[1;32m    333\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m    334\u001b[0m                                fileobj,\n\u001b[1;32m    335\u001b[0m                                offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset,\n\u001b[1;32m    336\u001b[0m                                order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder,\n\u001b[1;32m    337\u001b[0m                                mmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmap)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfileslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                     \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lock\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/fileslice.py:790\u001b[0m, in \u001b[0;36mfileslice\u001b[0;34m(fileobj, sliceobj, shape, dtype, offset, order, heuristic, lock)\u001b[0m\n\u001b[1;32m    787\u001b[0m segments, sliced_shape, post_slicers \u001b[38;5;241m=\u001b[39m calc_slicedefs(\n\u001b[1;32m    788\u001b[0m     sliceobj, shape, itemsize, offset, order)\n\u001b[1;32m    789\u001b[0m n_bytes \u001b[38;5;241m=\u001b[39m reduce(operator\u001b[38;5;241m.\u001b[39mmul, sliced_shape, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m itemsize\n\u001b[0;32m--> 790\u001b[0m arr_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m sliced \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(sliced_shape, dtype, buffer\u001b[38;5;241m=\u001b[39marr_data, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sliced[post_slicers]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/fileslice.py:687\u001b[0m, in \u001b[0;36mread_segments\u001b[0;34m(fileobj, segments, n_bytes, lock)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset, length \u001b[38;5;129;01min\u001b[39;00m segments:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m--> 687\u001b[0m         \u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;28mbytes\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(fileobj\u001b[38;5;241m.\u001b[39mread(length))\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m!=\u001b[39m n_bytes:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/nibabel/openers.py:168\u001b[0m, in \u001b[0;36mOpener.seek\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseek\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/gzip.py:392\u001b[0m, in \u001b[0;36mGzipFile.seek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m READ:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_not_closed()\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/_compression.py:143\u001b[0m, in \u001b[0;36mDecompressReader.seek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Read and discard data until we reach the desired position.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m offset \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_BUFFER_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/gzip.py:495\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m    493\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 495\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "save_model=1\n",
    "outdir=\"models/class_pet\"\n",
    "os.makedirs(outdir,exist_ok=True)\n",
    "\n",
    "loss_history=[]\n",
    "val_loss_history=[]\n",
    "# pbar=tqdm.tqdm(range(EPOCHS))\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    ## TRAINING\n",
    "    loss_tmp=[]\n",
    "    val_loss_tmp=[]\n",
    "    \n",
    "    pbar=tqdm.tqdm(train_dataloader)\n",
    "    epoch_acc=[]\n",
    "    y_list=[]\n",
    "    y_pred_list=[]\n",
    "    for x,y in pbar:\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        y_pred=model(x)\n",
    "\n",
    "        y_pred_list.append(y_pred.detach().cpu())\n",
    "        y_list.append(y.cpu())\n",
    "        \n",
    "        \n",
    "        #compute bayesian_loss\n",
    "        loss=criterion(y_pred,y)\n",
    "        kl = kl_loss(model)\n",
    "        \n",
    "        loss = loss + kl_weight*kl\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        pbar.set_description(f\"epoch {epoch} loss: {loss.item()}\")\n",
    "        loss_tmp.append(loss.item())\n",
    "        wandb.log({\"loss\":loss.item()})\n",
    "        \n",
    "    loss_history.append(np.mean(loss_tmp))\n",
    "    y_list=torch.cat(y_list,0)\n",
    "    y_pred_list=torch.cat(y_pred_list,0)\n",
    "    \n",
    "    acc=(y_list==y_pred_list.argmax(dim=1)).sum()/len(y_list)\n",
    "    wandb.log({\"train_acc\": acc})\n",
    "    epoch_acc.append(acc.numpy())\n",
    "    \n",
    "        \n",
    "    ## VALIDATION\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar_val=tqdm.tqdm(test_dataloader)\n",
    "        y_list=[]\n",
    "        y_pred_list=[]\n",
    "        \n",
    "        for x,y in pbar_val:\n",
    "        \n",
    "        \n",
    "            x,y=x.to(device),y.to(device)\n",
    "            y_pred=model(x)\n",
    "\n",
    "\n",
    "            #compute masked_loss\n",
    "            loss=criterion(y_pred,y)\n",
    "            kl = kl_loss(model)\n",
    "        \n",
    "            loss = loss + kl_weight*kl\n",
    "            \n",
    "            y_pred_list.append(y_pred.detach().cpu())\n",
    "            y_list.append(y.cpu())\n",
    "\n",
    "            pbar_val.set_description(f\"val epoch {epoch} val loss: {loss.item()}\")\n",
    "            val_loss_tmp.append(loss.item())\n",
    "            wandb.log({\"val_loss\":loss.item()})\n",
    "            \n",
    "        y_list=torch.cat(y_list,0)\n",
    "        y_pred_list=torch.cat(y_pred_list,0)\n",
    "        val_loss_history.append(np.mean(val_loss_tmp))\n",
    "        acc=(y_list==y_pred_list.argmax(dim=1)).sum()/len(y_list)\n",
    "        wandb.log({\"val_acc\": acc})\n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch%save_model==0:\n",
    "        ## SAVE MODEL\n",
    "        torch.save(model.state_dict(),f\"{outdir}_{epoch}.pt\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7f213d8-9109-4d25-b86d-202b6a0fe95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbd77b87fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history,label=\"loss\")\n",
    "plt.plot(val_loss_history,label=\"val_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae6a4a4-1081-42c4-9977-4b03d37f711e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43my_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m(),y_pred_list\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_list.numpy(),y_pred_list.argmax(dim=1).numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a04f97-76f9-4ae1-90ff-8d63b835e3b1",
   "metadata": {},
   "source": [
    "## Averaged Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdac372a-182c-473a-9c9a-a65d3ff80de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.57      0.84      0.68        19\n",
      "         2.0       0.62      0.53      0.57        15\n",
      "\n",
      "    accuracy                           0.59        41\n",
      "   macro avg       0.40      0.46      0.42        41\n",
      "weighted avg       0.49      0.59      0.52        41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_val=np.array([])\n",
    "y_pred_val_std=np.array([])\n",
    "\n",
    "\n",
    "y_val=np.array([])\n",
    "\n",
    "averages=100\n",
    "\n",
    "soft=nn.Softmax(dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm.tqdm(test_dataloader):\n",
    "        \n",
    "        guess=[]\n",
    "        for i in range(averages):\n",
    "            x=x.to(device)\n",
    "            guess.append(soft(model(x)).cpu().numpy())\n",
    "        y_pred_val=np.append(y_pred_val,np.array(guess).mean(axis=0))\n",
    "        y_pred_val_std=np.append(y_pred_val_std,np.array(guess).std(axis=0))\n",
    "        \n",
    "        y_val=np.append(y_val,y)\n",
    "\n",
    "y_pred_val=y_pred_val.reshape((-1,3))\n",
    "y_pred_val_std=y_pred_val_std.reshape((-1,3))\n",
    "\n",
    "y_val=y_val.reshape((len(y_pred_val),-1))\n",
    "\n",
    "print(\"ORIGINAL\")\n",
    "print(classification_report(y_val.squeeze(),np.argmax(y_pred_val,-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a403d9-8f93-4640-ad98-56c490f4e495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTING TRUSTHWORTHY PREDICTIONS\n",
      "[INFO] The network is valid is 0.6829268292682927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.65      0.87      0.74        15\n",
      "         2.0       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.42      0.50      0.46        28\n",
      "weighted avg       0.53      0.64      0.58        28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "keep_if_below=0.4\n",
    "\n",
    "print(\"COMPUTING TRUSTHWORTHY PREDICTIONS\")\n",
    "valid_pred=[]\n",
    "valid_true=[]\n",
    "for j in range(len(y_pred_val)):\n",
    "    idx=np.argmax(y_pred_val[j])\n",
    "    if y_pred_val_std[j][idx]<keep_if_below:\n",
    "        valid_pred.append(idx)\n",
    "        valid_true.append(y_val[j])\n",
    "print(f\"[INFO] The network is valid is {len(valid_pred)/len(y_pred_val)}\")\n",
    "print(classification_report(valid_true,valid_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ef430-0472-42d8-8008-790f284ff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
